# === docker-compose.dev.yml (SITL Development Setup) ===
#
# This file configures the development environment for PX4 SITL simulation.
# It uses UDP communication for the Micro XRCE-DDS Agent to connect to PX4 SITL.
#
# By default, it's configured for a single drone (drone1) with:
# - ROS 2 node name: drone1
# - Drone name: drone1
# - PX4 namespace: /fmu/ (for MAV_SYS_ID=1)
# - MAVLink System ID: 1
#
# MULTI-DRONE SETUP:
# To run multiple drones in SITL:
# 1. Copy this file for each additional drone (e.g., docker-compose.dev.drone2.yml)
# 2. Change the service name to be unique (e.g., drone_core2)
# 3. Update the container_name to be unique (e.g., drone_core_node2)
# 4. Update the command section for each drone with its specific configuration:
#    - __node: Unique ROS 2 node name (e.g., drone2)
#    - drone_name: Logical drone name (e.g., drone2)
#    - px4_namespace: PX4 topic namespace (e.g., /px4_1/fmu/ for MAV_SYS_ID=2)
#    - mav_sys_id: Unique MAVLink System ID (e.g., 2)
#
# Run with: docker compose -f docker-compose.dev.yml up -d
#

services:
  # --- Drone Core Service ---
  # Runs the main drone control logic (drone_core node)
  drone_core: # Service name (must be unique across all compose files)
    build:
      context: .
      dockerfile: drone_core.dev.Dockerfile
    container_name: drone_core_node # Explicit name for the running container
    network_mode: "host" # ESSENTIAL: Use the host's network for Tailscale & agent comms
    restart: unless-stopped # Optional: Restart policy
    volumes:
      - ../../src:/root/ws_droneOS/src
      - ../../build:/root/ws_droneOS/build
      - ../../install:/root/ws_droneOS/install
      - ../../logs:/root/ws_droneOS/logs
      # Mount the FastDDS config file
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
    environment:
      # Set the ROS 2 DDS implementation (ensure it matches your setup)
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      # Increase ROS log verbosity
      - ROS_LOG_SEVERITY_THRESHOLD=debug
      # DDS Domain ID (must match across all containers)
      - ROS_DOMAIN_ID=0
      # DDS Discovery settings (use SIMPLE to match other containers on srv01)
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
    depends_on:
      # Ensure the agent starts before the core logic
      - micro_agent
    # --- COMMAND OVERRIDE (CRITICAL) ---
    # Provides the specific arguments for THIS drone.
    # The ENTRYPOINT script will source setup files first
    command:
      - bash
      - -c
      - |
        . /opt/ros/humble/setup.bash
        cd /root/ws_droneOS
        colcon build --packages-select drone_interfaces px4_msgs drone_core
        . install/setup.bash
        ros2 run drone_core drone_core --ros-args \
          -r __node:=drone1 \
          -p drone_name:=drone1 \
          -p px4_namespace:=/fmu/ \
          -p mav_sys_id:=1

  # --- Micro XRCE-DDS Agent Service ---
  # Bridges communication between ROS 2 (DDS) and PX4 SITL instances
  # This agent is shared between all drones in the development environment
  micro_agent:
    # The Micro-XRCE-DDS-Agent source and build directories are mounted from the host.
    # You only need to rebuild the agent if you change the source code or delete the build artifacts.
    # The compiled binary and build directory persist across container restarts due to the volume mount.
    #
    # To build and run the agent inside the container:
    # 1. docker compose -f docker/dev/docker-compose.dev.drone1.yml exec micro_agent bash
    # 2. cd /root/ws_droneOS/Micro-XRCE-DDS-Agent
    # 3. mkdir build && cd build
    # 4. cmake ..
    # 5. make
    # 6. make install
    # 7. ldconfig /usr/local/lib/
    # 8. ./MicroXRCEAgent udp4 -p 8888
    build:
      context: .
      dockerfile: micro_agent.dev.Dockerfile
    container_name: micro_agent_service
    network_mode: "host"
    restart: unless-stopped
    environment:
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      - ROS_LOG_SEVERITY_THRESHOLD=debug
      # DDS Domain ID (must match across all containers)
      - ROS_DOMAIN_ID=0
      # DDS Discovery settings
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
      # Whitelist all interfaces for Fast-RTPS (temporary for testing)
      - FASTRTPS_WHITELIST_INTERFACES=all
    command:
      - bash
      - -c
      - |
        cd /root/ws_droneOS/Micro-XRCE-DDS-Agent/build && \
        ./MicroXRCEAgent udp4 -p 8888
    volumes:
      - ../../Micro-XRCE-DDS-Agent:/root/ws_droneOS/Micro-XRCE-DDS-Agent
      # Mount the FastDDS config file
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
    # Note: Ensure the user running Docker on the host (e.g., 'rodrigo') has permission for /dev/ttyUSB0 (belongs to 'dialout' group).
    # If not, run: sudo usermod -a -G dialout rodrigo (or relevant user) and then REBOOT or log out/in.

# --- Camera Service ---
  # Builds libcamera and rpicam-apps from source for camera support
  camera_service:
    build:
      context: .
      dockerfile: camera.dev.Dockerfile
    container_name: camera_service_node
    network_mode: "host"
    restart: unless-stopped
    privileged: true
    group_add:
      - video
    devices:
      - /dev/vchiq
      - /dev/video0
      - /dev/v4l-subdev0
      - /dev/media0
      - /dev/media1
    environment:
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      - ROS_LOG_SEVERITY_THRESHOLD=debug
      # DDS Domain ID (must match across all containers)
      - ROS_DOMAIN_ID=0
      # DDS Discovery settings      
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
      - FASTRTPS_WHITELIST_INTERFACES=all
      - DRONE_NAME=drone1 # Set a default drone name
    volumes:
      # Mount the FastDDS config file
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
    command:
      - bash
      - -c
      - |
          /lib/systemd/systemd-udevd --daemon
          udevadm trigger
          . /opt/ros/humble/setup.bash
          . /root/ros2_ws/install/setup.bash
          # Create a dummy calibration file to suppress warnings initially
          mkdir -p /root/.ros/camera_info/
          touch "/root/.ros/camera_info/drone1_camera.yaml"
          # Start web_video_server in background
          ros2 run web_video_server web_video_server --ros-args \
            -p port:=8080 \
            -p default_stream_type:='ros_compressed' \
            -p quality:=80 \
            -p framerate:=15 &
          # Start camera node
          ros2 run camera_ros camera_node --ros-args -p camera:=0 -p width:=1280 -p height:=720 -p format:=XRGB8888 -p frame_id:="drone1_camera_link" -p camera_info_url:="file:///root/.ros/camera_info/drone1_camera.yaml"

  # --- Simulated Camera Service (for SITL/Gazebo) ---
  # Bridges Gazebo camera to ROS2 and serves MJPEG stream
  # Use this instead of camera_service when running simulation
  sim_camera:
    build:
      context: .
      dockerfile: sim_camera.dev.Dockerfile
    container_name: sim_camera_node
    network_mode: "host"
    restart: unless-stopped
    environment:
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      - ROS_DOMAIN_ID=0
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
      - FASTRTPS_WHITELIST_INTERFACES=all
      # Gazebo camera topic to bridge (default: /camera)
      - GZ_CAMERA_TOPIC=/camera
    volumes:
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
    command:
      - bash
      - -c
      - |
        . /opt/ros/humble/setup.bash
        # Only run web_video_server - image_bridge runs on host
        # (Gazebo Transport doesn't work across host/container boundary)
        ros2 run web_video_server web_video_server --ros-args \
          -p port:=8080 \
          -p default_stream_type:='mjpeg' \
          -p quality:=80 \
          -p framerate:=30

  # --- Rosbridge Server (for Web UI) ---
  # Provides WebSocket/JSON interface to ROS2 for the web frontend
  rosbridge:
    image: ros:humble
    container_name: rosbridge_server
    network_mode: "host"
    restart: unless-stopped
    environment:
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      - ROS_DOMAIN_ID=0
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
    volumes:
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
      - ../../install:/root/ws_droneOS/install:ro
    command:
      - bash
      - -c
      - |
        apt-get update && apt-get install -y ros-humble-rosbridge-suite
        . /opt/ros/humble/setup.bash
        . /root/ws_droneOS/install/setup.bash 2>/dev/null || true
        echo 'Starting rosbridge on port 9090...'
        ros2 launch rosbridge_server rosbridge_websocket_launch.xml port:=9090

  # --- AI Agent System Service ---
  agent_system:
    env_file:
      - ../../.env # Load environment variables from .env file at the project root
    build:
      context: ../../
      dockerfile: docker/dev/agent_system.dev.Dockerfile
    container_name: agent_system_node
    stdin_open: true # Keep STDIN open for interactive mode
    tty: true        # Allocate a TTY for interactive mode
    network_mode: "host" # Essential for ROS 2 DDS communication and service discovery
    restart: unless-stopped
    volumes:
      # Mount the agent system source code for live development
      - ../../src/drone_agent_system:/root/ws_droneOS/src/drone_agent_system
      # Mount the FastDDS config file
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
      # If you have a .env file for secrets like OPENAI_API_KEY at the root of ws_droneOS
      # - ../../.env:/root/ws_droneOS/.env 
    environment:
      # IMPORTANT: Set your OPENAI_API_KEY. 
      # It's best to use Docker secrets or pass it from the host environment.
      # Example: OPENAI_API_KEY=${OPENAI_API_KEY} (if OPENAI_API_KEY is set on host)
      # Or load from a .env file if you mount one (see volumes)
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      - ROS_DOMAIN_ID=0 # Must match other services
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
      - PYTHONUNBUFFERED=1 # For immediate Python print output
      # Add any other environment variables your agent might need

  # --- Edge TPU Object Detector Service ---
  # Runs object detection using Google Coral Edge TPU accelerator
  # WORKING: ROS 2 Galactic + Edge TPU + Ubuntu 20.04 + Python 3.8
  object_detector:
    build:
      context: .
      dockerfile: object_detector_ros2.dev.Dockerfile
    container_name: object_detector_node
    stdin_open: true
    tty: true
    network_mode: "host"
    restart: unless-stopped
    privileged: true # Required for USB device access
    volumes:
      # Mount models directory
      - ../../models:/workspace/models
      # Mount source code for custom detector development
      - ../../src/object_detector:/workspace/src
      # Mount logs
      - ../../logs:/workspace/logs
      # Mount the FastDDS config file
      - ../../fastdds_config_dev_simple.xml:/root/ws_droneOS/fastdds_config.xml
    devices:
      # Pass through USB devices (Edge TPU will show up as a USB device)
      - /dev/bus/usb:/dev/bus/usb
    environment:
      - RMW_IMPLEMENTATION=rmw_fastrtps_cpp
      - ROS_DOMAIN_ID=0
      - FASTRTPS_DEFAULT_PROFILES_FILE=/root/ws_droneOS/fastdds_config.xml
      - PYTHONUNBUFFERED=1


  # --- Frontend Development Server ---
  # React web UI with hot reload
  frontend:
    build:
      context: ../..
      dockerfile: docker/dev/frontend.dev.Dockerfile
    container_name: frontend_node
    network_mode: "host"
    restart: unless-stopped
    volumes:
      - ../../web_interface/frontend:/app
      - /app/node_modules
    environment:
      - REACT_APP_SERVER_HOST=localhost
    working_dir: /app
    command: node server.js

  # --- OpenClaw Web UI Proxy ---
  # Keeps the OpenClaw gateway token server-side; browser hits :3031 over HTTP.
  openclaw_proxy:
    build:
      context: ../..
      dockerfile: docker/dev/openclaw_proxy.dev.Dockerfile
    container_name: openclaw_proxy_node
    network_mode: "host"
    restart: unless-stopped
    volumes:
      - ../../web_interface/backend/openclaw_proxy.py:/app/openclaw_proxy.py:ro
      - ${HOME}/.openclaw/openclaw.json:/root/.openclaw/openclaw.json:ro
      - ${HOME}/.openclaw/workspace:/root/.openclaw/workspace:ro
    environment:
      - OPENCLAW_GATEWAY_WS_URL=ws://127.0.0.1:18789
      - OPENCLAW_PROXY_BIND=0.0.0.0
      - OPENCLAW_PROXY_PORT=3031

  # --- Rosbridge WebSocket Relay (VPS only) ---
  # Proxies WebSocket connections to srv01's rosbridge over Tailscale
  # Use this on VPS instead of rosbridge service
  rosbridge_relay:
    build:
      context: ../..
      dockerfile: docker/dev/rosbridge_relay.dev.Dockerfile
    container_name: rosbridge_relay_node
    network_mode: "host"
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1

  # --- Camera MJPEG Stream Proxy (VPS only) ---
  # Proxies camera stream from srv01 to VPS
  # Use this on VPS to relay camera feed over Tailscale
  camera_proxy:
    build:
      context: ../..
      dockerfile: docker/dev/camera_proxy.dev.Dockerfile
    container_name: camera_proxy_node
    network_mode: "host"
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1

volumes:
  logs: # Declares that the host path './logs' is expected
    driver: local
